#!/usr/bin/env python3
"""
Test script para verificar el funcionamiento del pipeline de clasificaciÃ³n de incidencias Naturgy
"""

import pandas as pd
import numpy as np
from naturgy_ai_incident_classifier import NaturgyIncidentClassifier, IncidentAnalysisRunner

def test_preprocessing():
    """Prueba las funciones de preprocesamiento"""
    print("ðŸ§ª Probando preprocesamiento...")
    
    classifier = NaturgyIncidentClassifier()
    
    # Datos de prueba
    test_data = pd.DataFrame({
        'Resumen': [
            'Buenos dÃ­as, tengo un error en el sistema CUPS ES0022000005514737AZ1P',
            'Solicito extracciÃ³n de listado de facturaciÃ³n',
            'Fail DECMD040P Job Name: DECMD040P Node: DELTAMAYPROD'
        ],
        'Notas': [
            'Por favor ayuda con este problema urgente',
            'Necesito el informe para el cliente',
            'Excessive batch process error'
        ],
        'Tipo de Ticket': [
            'Incident',
            'Service Request',
            'Incident'
        ]
    })
    
    # Procesar
    processed = classifier.preprocessor.process_dataframe(test_data)
    processed = classifier.entity_extractor.extract_entities(processed)
    
    print("âœ… Texto original:", test_data['Resumen'].iloc[0])
    print("âœ… Texto procesado:", processed['processed_text'].iloc[0])
    print("âœ… Entidades extraÃ­das:", processed['entities'].iloc[0])
    print("âœ… Features de entidades:", [col for col in processed.columns if col.startswith('has_')])
    
    return processed

def test_clustering():
    """Prueba el clustering"""
    print("\nðŸ§ª Probando clustering...")
    
    classifier = NaturgyIncidentClassifier()
    
    # Crear datos sintÃ©ticos mÃ¡s grandes para clustering
    test_texts = [
        'error sistema cups modificar baja',
        'error sistema cups modificar alta',
        'error sistema cups cambio fecha',
        'extracciÃ³n informe listado facturaciÃ³n',
        'extracciÃ³n informe listado consulta',
        'extracciÃ³n informe datos cliente',
        'fail batch job proceso error',
        'fail batch job name error',
        'fail batch proceso sistema'
    ]
    
    test_data = pd.DataFrame({
        'Resumen': test_texts,
        'Notas': [''] * len(test_texts),
        'Tipo de Ticket': ['Incident'] * len(test_texts)
    })
    
    # Procesar y hacer clustering
    processed = classifier.preprocessor.process_dataframe(test_data)
    processed = classifier.entity_extractor.extract_entities(processed)
    
    cluster_results = classifier.clusterer.cluster_incidents(processed)
    
    print(f"âœ… Clusters encontrados: {cluster_results['n_clusters']}")
    print(f"âœ… Silhouette score: {cluster_results['silhouette_score']:.3f}")
    print(f"âœ… DistribuciÃ³n de clusters: {cluster_results['cluster_sizes']}")
    
    return cluster_results

def test_classification():
    """Prueba la clasificaciÃ³n completa"""
    print("\nðŸ§ª Probando clasificaciÃ³n completa...")
    
    # Usar datos sintÃ©ticos para prueba rÃ¡pida
    test_data = pd.DataFrame({
        'Ticket ID': [f'TEST_{i:06d}' for i in range(20)],
        'Resumen': [
            'Error en CUPS ES0022000005514737AZ1P no permite modificar',
            'Solicito extracciÃ³n de listado de facturaciÃ³n mensual',
            'Fail DECMD040P batch process error',
            'Problema con alta de contrato en sistema',
            'Consulta funcional sobre proceso de baja',
            'Error de conectividad en infraestructura',
            'ActualizaciÃ³n masiva de datos pendiente',
            'Incidencia tÃ©cnica en servidor principal',
            'Reporte de anÃ¡lisis de consumos requerido',
            'ModificaciÃ³n de fecha en lÃ­nea de oferta',
            'Error en CUPS ES0234150261861527GB lectura',
            'ExtracciÃ³n de datos para auditorÃ­a necesaria',
            'Batch job DELED100P failed execution',
            'Cambio de titular sin subrogaciÃ³n requerido',
            'Consulta sobre operativa de facturaciÃ³n',
            'Error infraestructura comunicaciones red',
            'ActualizaciÃ³n datos cliente origen usuario',
            'Problema tÃ©cnico aplicaciÃ³n Delta',
            'Listado facturas conceptos importe cero',
            'GestiÃ³n CUPS direcciones incorrectas'
        ],
        'Notas': ['DescripciÃ³n adicional del problema'] * 20,
        'Tipo de Ticket': ['Incident'] * 10 + ['Service Request'] * 10
    })
    
    classifier = NaturgyIncidentClassifier()
    
    try:
        # Guardar datos sintÃ©ticos y entrenar
        print("ðŸ“Š Entrenando modelo con datos sintÃ©ticos...")
        test_data.to_excel('temp_test_data.xlsx', index=False)
        results = classifier.train_pipeline('temp_test_data.xlsx')
        
        # Limpiar archivo temporal
        import os
        if os.path.exists('temp_test_data.xlsx'):
            os.remove('temp_test_data.xlsx')
        
        # Probar clasificaciÃ³n de nuevas incidencias
        test_incidents = [
            "Error en sistema CUPS no permite calcular facturas",
            "Solicito informe de extracciones mensuales",
            "Fallo en proceso batch de datos masivos"
        ]
        
        print("\nðŸŽ¯ Probando clasificaciÃ³n de nuevas incidencias:")
        for incident in test_incidents:
            prediction = classifier.classify_incident(incident)
            print(f"  ðŸ“ Incidencia: {incident}")
            print(f"  ðŸ·ï¸  Tipo predicho: {prediction['predicted_type']}")
            print(f"  ðŸŽ¯ Confianza: {prediction['confidence']:.3f}")
            print(f"  ðŸ“‹ InformaciÃ³n: {prediction['type_info']['nombre'] if prediction['type_info'] else 'N/A'}")
            print()
        
        print("âœ… ClasificaciÃ³n completada exitosamente")
        return results
        
    except Exception as e:
        print(f"âŒ Error en clasificaciÃ³n: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_complete_pipeline():
    """Prueba el pipeline completo con archivo real si estÃ¡ disponible"""
    print("\nðŸ§ª Probando pipeline completo...")
    
    try:
        # Intentar con archivo real
        import os
        if os.path.exists('infomation.xlsx'):
            print("ðŸ“Š Usando datos reales de infomation.xlsx")
            IncidentAnalysisRunner.run_complete_analysis('infomation.xlsx', './test_results')
            print("âœ… Pipeline completo ejecutado con datos reales")
        else:
            print("â„¹ï¸  Archivo infomation.xlsx no encontrado, usando datos sintÃ©ticos")
            
            # Crear dataset sintÃ©tico mÃ¡s grande
            synthetic_data = create_synthetic_dataset(100)
            synthetic_data.to_excel('test_synthetic_data.xlsx', index=False)
            
            IncidentAnalysisRunner.run_complete_analysis('test_synthetic_data.xlsx', './test_results')
            print("âœ… Pipeline completo ejecutado con datos sintÃ©ticos")
            
    except Exception as e:
        print(f"âŒ Error en pipeline completo: {e}")
        import traceback
        traceback.print_exc()

def create_synthetic_dataset(n_samples: int) -> pd.DataFrame:
    """Crea un dataset sintÃ©tico para pruebas"""
    
    # Plantillas de incidencias por tipo
    templates = {
        'Error CUPS': [
            'Error en CUPS {cups} no permite {action}',
            'Problema con CUPS {cups} en proceso de {action}',
            'Incidencia tÃ©cnica CUPS {cups} fallo {action}'
        ],
        'ExtracciÃ³n Datos': [
            'Solicito extracciÃ³n de {report_type} para {period}',
            'Necesito listado de {report_type} del {period}',
            'Reporte de {report_type} requerido urgente'
        ],
        'Batch Process': [
            'Fail {job_name} batch process error',
            'Proceso {job_name} fallo en ejecuciÃ³n',
            'Job {job_name} terminated with errors'
        ],
        'Consulta Funcional': [
            'Consulta sobre proceso de {operation}',
            'InformaciÃ³n necesaria sobre {operation}',
            'Duda operativa relacionada con {operation}'
        ]
    }
    
    # Generar datos
    data = []
    for i in range(n_samples):
        template_type = np.random.choice(list(templates.keys()))
        template = np.random.choice(templates[template_type])
        
        # Rellenar plantilla con datos sintÃ©ticos
        if 'cups' in template:
            cups = f'ES{np.random.randint(1000, 9999)}{np.random.randint(1000, 9999)}{np.random.randint(1000, 9999)}{np.random.randint(1000, 9999)}XX1P'
            action = np.random.choice(['calcular', 'modificar', 'activar', 'dar baja'])
            text = template.format(cups=cups, action=action)
        elif 'report_type' in template:
            report_type = np.random.choice(['facturas', 'consumos', 'clientes', 'contratos'])
            period = np.random.choice(['enero 2025', 'febrero 2025', 'Ãºltimo trimestre'])
            text = template.format(report_type=report_type, period=period)
        elif 'job_name' in template:
            job_name = np.random.choice(['DECMD040P', 'DELED100P', 'DETFD251P'])
            text = template.format(job_name=job_name)
        elif 'operation' in template:
            operation = np.random.choice(['facturaciÃ³n', 'cambio titular', 'activaciÃ³n contrato'])
            text = template.format(operation=operation)
        else:
            text = template
        
        data.append({
            'Ticket ID': f'SYNTH_{i:06d}',
            'Resumen': text,
            'Notas': f'DescripciÃ³n adicional para incidencia {i}',
            'Tipo de Ticket': 'Incident' if np.random.random() > 0.3 else 'Service Request'
        })
    
    return pd.DataFrame(data)

if __name__ == "__main__":
    print("ðŸš€ INICIANDO PRUEBAS DEL PIPELINE NATURGY")
    print("=" * 60)
    
    # Ejecutar todas las pruebas
    test_preprocessing()
    test_clustering()
    test_classification()
    test_complete_pipeline()
    
    print("\n" + "=" * 60)
    print("âœ… TODAS LAS PRUEBAS COMPLETADAS")
